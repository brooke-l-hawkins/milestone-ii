{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "impressed-ideal",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "occasional-occasions",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-minneapolis",
   "metadata": {},
   "source": [
    "## Combine performance from multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "religious-sound",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_performance_files():\n",
    "    \"\"\"\n",
    "    Combine performance files into a single file\n",
    "    \"\"\"\n",
    "\n",
    "    # get files listed in performance directory\n",
    "    performance_directory = '../data/derived/performance'\n",
    "    performance_files = listdir(performance_directory)\n",
    "\n",
    "    # remove jupyter notebook checkpoints from file list\n",
    "    performance_files.remove('.ipynb_checkpoints')\n",
    "    # remove summary from file list if it already exists\n",
    "    if 'summary.csv' in performance_files:\n",
    "        performance_files.remove('summary.csv')\n",
    "    \n",
    "\n",
    "    # initialize dictionary of empty lists to track metrics across models\n",
    "    summary_dict = {'model_name':[],\n",
    "                    'dataset_name':[],\n",
    "                    'vector_name':[],\n",
    "                    'hyperparameter_name':[],\n",
    "                    'hyperparameter_value':[],\n",
    "                    'metric_name':[],\n",
    "                    'metric_value':[]}\n",
    "\n",
    "    # iterate over files\n",
    "    for file in performance_files:\n",
    "\n",
    "        # get model, vector, hyperparameter, and dataset name from file name\n",
    "        model_name, vector_string, hyperparameter_string, dataset_string = file.split('_')\n",
    "\n",
    "        # get dataset name from dataset string\n",
    "        dataset_name = dataset_string[:-(len('.csv'))]\n",
    "\n",
    "        # get vector name from vector string\n",
    "        vector_name = vector_string[len('vector'):]\n",
    "\n",
    "        # get hyperparameter name based on model name\n",
    "        if model_name == 'decisiontree':\n",
    "            hyperparameter_name = 'maxdepth'\n",
    "        elif model_name == 'svc':\n",
    "            hyperparameter_name = 'c'\n",
    "        elif model_name == 'mlp':\n",
    "            hyperparameter_name = 'alpha'\n",
    "\n",
    "        # get hyperparameter value from hyperparameter string\n",
    "        hyperparameter_value = hyperparameter_string[len(hyperparameter_name):]\n",
    "\n",
    "        # get metrics dataframe\n",
    "        metrics_df = pd.read_csv(performance_directory + '/' + file)\n",
    "\n",
    "        # iterate over metrics\n",
    "        for metric_name in metrics_df['metric']:\n",
    "\n",
    "            # get metric value\n",
    "            metric_value = metrics_df[metrics_df['metric'] == metric_name]['value'].values[0]\n",
    "\n",
    "            # save information to summary dictionary\n",
    "            summary_dict['model_name'].append(model_name)\n",
    "            summary_dict['dataset_name'].append(dataset_name)\n",
    "            summary_dict['vector_name'].append(vector_name)\n",
    "            summary_dict['hyperparameter_name'].append(hyperparameter_name)\n",
    "            summary_dict['hyperparameter_value'].append(hyperparameter_value)\n",
    "            summary_dict['metric_name'].append(metric_name)\n",
    "            summary_dict['metric_value'].append(metric_value)\n",
    "\n",
    "    # create dataframe from summary dictionary\n",
    "    summary_df = pd.DataFrame(summary_dict)\n",
    "\n",
    "    # write summary to CSV\n",
    "    filepath_out = performance_directory + '/' + 'summary.csv'\n",
    "    summary_df.to_csv(filepath_out, index=False)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "other-legislation",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_performance_files()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
