{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "orange-texture",
   "metadata": {},
   "source": [
    "Note: This script will not run without twitter API keys."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-howard",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "upper-costa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in /opt/conda/lib/python3.7/site-packages (3.10.0)\r\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /opt/conda/lib/python3.7/site-packages (from tweepy) (2.25.1)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tweepy) (1.3.0)\r\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tweepy) (1.15.0)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->tweepy) (3.0.1)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy) (2.10)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy) (4.0.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy) (2020.12.5)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy) (1.26.3)\r\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy) (1.7.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "metric-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import tweepy as tw\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-tourism",
   "metadata": {},
   "source": [
    "# Load Tweet IDS\n",
    "\n",
    "### Load Waseem 2016 IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "legendary-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadWaseem(filepath_in):\n",
    "    \n",
    "    # read in tweet IDs\n",
    "    df = pd.read_csv(filepath_or_buffer=filepath_in,\n",
    "                    sep='\\t',\n",
    "                    index_col=False,\n",
    "                    usecols=['TweetID','Expert'])\n",
    "\n",
    "    # rename columns\n",
    "    df.rename(columns={'TweetID':'tweet_id', 'Expert':'label'}, inplace=True)\n",
    "    \n",
    "    # map label\n",
    "    df['label'] = df['label'].map({'neither':0, 'racism':1, 'sexism':2, 'both':3})\n",
    "    \n",
    "    # return dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fitted-acquisition",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load tweet ids\n",
    "waseem_id_df = loadWaseem(filepath_in = '../data/downloaded/hatespeech-master/NLP+CSS_2016.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-plumbing",
   "metadata": {},
   "source": [
    "### Load Jha Mamidi IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baking-internet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadJhaMamidi(hostile_filepath_in, benevolent_filepath_in):\n",
    "    \n",
    "    # read in tweet IDs\n",
    "    hostile_df    = pd.read_csv(filepath_or_buffer=hostile_filepath_in,\n",
    "                                header=None,\n",
    "                                names=['tweet_id'])\n",
    "    benevolent_df = pd.read_csv(filepath_or_buffer=benevolent_filepath_in,\n",
    "                                header=None,\n",
    "                                names=['tweet_id'])\n",
    "\n",
    "    # add labels\n",
    "    hostile_df['label'] = 4\n",
    "    benevolent_df['label'] = 5\n",
    "    \n",
    "    # stack dataframes\n",
    "    df = pd.concat([hostile_df, benevolent_df])\n",
    "    \n",
    "    # return dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "organizational-cleaners",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tweet ids\n",
    "jhamamidi_id_df = loadJhaMamidi(hostile_filepath_in='../data/downloaded/NLP_CSS_2017-master/hostile_sexist.tsv',\n",
    "                             benevolent_filepath_in='../data/downloaded/NLP_CSS_2017-master/benevolent_sexist.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-ranch",
   "metadata": {},
   "source": [
    "### Combine IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "interested-electricity",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6338</th>\n",
       "      <td>6338</td>\n",
       "      <td>575544108325978113</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>150</td>\n",
       "      <td>575860144355041280</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15142</th>\n",
       "      <td>4855</td>\n",
       "      <td>839681051605688320</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>569612886722486272</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5204</th>\n",
       "      <td>5204</td>\n",
       "      <td>598776035379843072</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index            tweet_id  label\n",
       "6338    6338  575544108325978113      0\n",
       "150      150  575860144355041280      2\n",
       "15142   4855  839681051605688320      5\n",
       "92        92  569612886722486272      0\n",
       "5204    5204  598776035379843072      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine IDs into one dataframe\n",
    "id_df = pd.concat([waseem_id_df, jhamamidi_id_df])\n",
    "# reset indices\n",
    "id_df.reset_index(inplace=True)\n",
    "# quick peek\n",
    "id_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-struggle",
   "metadata": {},
   "source": [
    "# Query tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-reviewer",
   "metadata": {},
   "source": [
    "### Initialize Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "criminal-animal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeAPI(consumer_key, consumer_secret):\n",
    "    auth = tw.AppAuthHandler(consumer_key, consumer_secret)\n",
    "    api = tw.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "    return api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "virtual-somewhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize twitter API\n",
    "my_consumer_key = ''\n",
    "my_consumer_secret = ''\n",
    "api = initializeAPI(consumer_key=my_consumer_key,\n",
    "                    consumer_secret=my_consumer_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "approved-category",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @GemmaAnneStyles: Happy #womensday to all my sassy women, classy women, nasty women üíãüëßüèæüíñüë©üèº\\u200düî¨üëÑüëµüèº my fine women, alive women, gonna fight‚Ä¶'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick test\n",
    "api.get_status(839880162586071040).text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-desperate",
   "metadata": {},
   "source": [
    "### Query tweets based on IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "encouraging-bookmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryTweets(tweet_df, api, tweet_filepath_out, error_filepath_out, all_tweets=True, tweet_size=15):\n",
    "\n",
    "    # add column for tweet text\n",
    "    tweet_df['text'] = None\n",
    "    \n",
    "    # reorder columns\n",
    "    tweet_df = tweet_df[['tweet_id', 'text', 'label']]\n",
    "    \n",
    "    # initialize error counter\n",
    "    error_count = [0] * len(set(tweet_df['label']))\n",
    "\n",
    "    # define range for tweets to query\n",
    "    range_size = len(tweet_df) if all_tweets else tweet_size\n",
    "\n",
    "    # iterate over rows of dataframe\n",
    "    for i in range(range_size):\n",
    "        \n",
    "        # extract tweet id and label\n",
    "        tweet_id = tweet_df['tweet_id'][i]\n",
    "        tweet_label = tweet_df['label'][i]\n",
    "        \n",
    "        # try query\n",
    "        try:\n",
    "            # query tweet\n",
    "            tweet = api.get_status(tweet_id)\n",
    "            # extract text\n",
    "            tweet_text = tweet.text\n",
    "            \n",
    "        # catch exceptions\n",
    "        except:\n",
    "            # increase error counter\n",
    "            error_count[tweet_label] += 1\n",
    "            # no change to text\n",
    "            tweet_text = None\n",
    "\n",
    "        # update record\n",
    "        tweet_df['text'][i] = tweet_text\n",
    "        \n",
    "        # print progress every 100 tweets\n",
    "        if (i+1)%100 == 0:\n",
    "            print((i+1), 'tweets queried of', range_size, 'total tweets.')\n",
    "\n",
    "    # create error tracking dataframe\n",
    "    error_df = pd.DataFrame({'label':[i for i in range(len(error_count))],\n",
    "                             'error_count':error_count})\n",
    "\n",
    "    # write tweets and error tracker to csv\n",
    "    tweet_df.to_csv(path_or_buf=tweet_filepath_out, index=False)\n",
    "    error_df.to_csv(path_or_buf=error_filepath_out, index=False)\n",
    "    \n",
    "    # print error count\n",
    "    print(f'There were {sum(error_count)} total errors of {range_size} total tweets.')\n",
    "    for i in range(len(error_count)):\n",
    "        print(f'    Label {i} had {error_count[i]} errors.')\n",
    "    \n",
    "    # return tweets\n",
    "    return tweet_df, error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "peripheral-satin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 tweets queried of 17492 total tweets.\n",
      "200 tweets queried of 17492 total tweets.\n",
      "300 tweets queried of 17492 total tweets.\n",
      "400 tweets queried of 17492 total tweets.\n",
      "500 tweets queried of 17492 total tweets.\n",
      "600 tweets queried of 17492 total tweets.\n",
      "700 tweets queried of 17492 total tweets.\n",
      "800 tweets queried of 17492 total tweets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 tweets queried of 17492 total tweets.\n",
      "1000 tweets queried of 17492 total tweets.\n",
      "1100 tweets queried of 17492 total tweets.\n",
      "1200 tweets queried of 17492 total tweets.\n",
      "1300 tweets queried of 17492 total tweets.\n",
      "1400 tweets queried of 17492 total tweets.\n",
      "1500 tweets queried of 17492 total tweets.\n",
      "1600 tweets queried of 17492 total tweets.\n",
      "1700 tweets queried of 17492 total tweets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800 tweets queried of 17492 total tweets.\n",
      "1900 tweets queried of 17492 total tweets.\n",
      "2000 tweets queried of 17492 total tweets.\n",
      "2100 tweets queried of 17492 total tweets.\n",
      "2200 tweets queried of 17492 total tweets.\n",
      "2300 tweets queried of 17492 total tweets.\n",
      "2400 tweets queried of 17492 total tweets.\n",
      "2500 tweets queried of 17492 total tweets.\n",
      "2600 tweets queried of 17492 total tweets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700 tweets queried of 17492 total tweets.\n",
      "2800 tweets queried of 17492 total tweets.\n",
      "2900 tweets queried of 17492 total tweets.\n",
      "3000 tweets queried of 17492 total tweets.\n",
      "3100 tweets queried of 17492 total tweets.\n",
      "3200 tweets queried of 17492 total tweets.\n",
      "3300 tweets queried of 17492 total tweets.\n",
      "3400 tweets queried of 17492 total tweets.\n",
      "3500 tweets queried of 17492 total tweets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600 tweets queried of 17492 total tweets.\n",
      "3700 tweets queried of 17492 total tweets.\n",
      "3800 tweets queried of 17492 total tweets.\n",
      "3900 tweets queried of 17492 total tweets.\n",
      "4000 tweets queried of 17492 total tweets.\n",
      "4100 tweets queried of 17492 total tweets.\n",
      "4200 tweets queried of 17492 total tweets.\n",
      "4300 tweets queried of 17492 total tweets.\n",
      "4400 tweets queried of 17492 total tweets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500 tweets queried of 17492 total tweets.\n",
      "4600 tweets queried of 17492 total tweets.\n",
      "4700 tweets queried of 17492 total tweets.\n",
      "4800 tweets queried of 17492 total tweets.\n",
      "4900 tweets queried of 17492 total tweets.\n",
      "5000 tweets queried of 17492 total tweets.\n",
      "5100 tweets queried of 17492 total tweets.\n",
      "5200 tweets queried of 17492 total tweets.\n",
      "5300 tweets queried of 17492 total tweets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5400 tweets queried of 17492 total tweets.\n",
      "5500 tweets queried of 17492 total tweets.\n",
      "5600 tweets queried of 17492 total tweets.\n",
      "5700 tweets queried of 17492 total tweets.\n",
      "5800 tweets queried of 17492 total tweets.\n",
      "5900 tweets queried of 17492 total tweets.\n",
      "6000 tweets queried of 17492 total tweets.\n",
      "6100 tweets queried of 17492 total tweets.\n",
      "6200 tweets queried of 17492 total tweets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6300 tweets queried of 17492 total tweets.\n",
      "6400 tweets queried of 17492 total tweets.\n",
      "6500 tweets queried of 17492 total tweets.\n",
      "6600 tweets queried of 17492 total tweets.\n",
      "6700 tweets queried of 17492 total tweets.\n",
      "6800 tweets queried of 17492 total tweets.\n",
      "6900 tweets queried of 17492 total tweets.\n",
      "7000 tweets queried of 17492 total tweets.\n",
      "7100 tweets queried of 17492 total tweets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200 tweets queried of 17492 total tweets.\n",
      "7300 tweets queried of 17492 total tweets.\n",
      "7400 tweets queried of 17492 total tweets.\n",
      "7500 tweets queried of 17492 total tweets.\n",
      "7600 tweets queried of 17492 total tweets.\n",
      "7700 tweets queried of 17492 total tweets.\n",
      "7800 tweets queried of 17492 total tweets.\n",
      "7900 tweets queried of 17492 total tweets.\n",
      "8000 tweets queried of 17492 total tweets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8100 tweets queried of 17492 total tweets.\n",
      "8200 tweets queried of 17492 total tweets.\n",
      "8300 tweets queried of 17492 total tweets.\n",
      "8400 tweets queried of 17492 total tweets.\n",
      "8500 tweets queried of 17492 total tweets.\n",
      "8600 tweets queried of 17492 total tweets.\n",
      "8700 tweets queried of 17492 total tweets.\n",
      "8800 tweets queried of 17492 total tweets.\n",
      "8900 tweets queried of 17492 total tweets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000 tweets queried of 17492 total tweets.\n",
      "9100 tweets queried of 17492 total tweets.\n",
      "9200 tweets queried of 17492 total tweets.\n",
      "9300 tweets queried of 17492 total tweets.\n",
      "9400 tweets queried of 17492 total tweets.\n",
      "9500 tweets queried of 17492 total tweets.\n",
      "9600 tweets queried of 17492 total tweets.\n",
      "9700 tweets queried of 17492 total tweets.\n",
      "9800 tweets queried of 17492 total tweets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9900 tweets queried of 17492 total tweets.\n",
      "10000 tweets queried of 17492 total tweets.\n",
      "10100 tweets queried of 17492 total tweets.\n",
      "10200 tweets queried of 17492 total tweets.\n",
      "10300 tweets queried of 17492 total tweets.\n",
      "10400 tweets queried of 17492 total tweets.\n",
      "10500 tweets queried of 17492 total tweets.\n",
      "10600 tweets queried of 17492 total tweets.\n",
      "10700 tweets queried of 17492 total tweets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10800 tweets queried of 17492 total tweets.\n",
      "10900 tweets queried of 17492 total tweets.\n",
      "11000 tweets queried of 17492 total tweets.\n",
      "11100 tweets queried of 17492 total tweets.\n",
      "11200 tweets queried of 17492 total tweets.\n",
      "11300 tweets queried of 17492 total tweets.\n",
      "11400 tweets queried of 17492 total tweets.\n",
      "11500 tweets queried of 17492 total tweets.\n",
      "11600 tweets queried of 17492 total tweets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11700 tweets queried of 17492 total tweets.\n",
      "11800 tweets queried of 17492 total tweets.\n",
      "11900 tweets queried of 17492 total tweets.\n",
      "12000 tweets queried of 17492 total tweets.\n",
      "12100 tweets queried of 17492 total tweets.\n",
      "12200 tweets queried of 17492 total tweets.\n",
      "12300 tweets queried of 17492 total tweets.\n",
      "12400 tweets queried of 17492 total tweets.\n",
      "12500 tweets queried of 17492 total tweets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12600 tweets queried of 17492 total tweets.\n",
      "12700 tweets queried of 17492 total tweets.\n",
      "12800 tweets queried of 17492 total tweets.\n",
      "12900 tweets queried of 17492 total tweets.\n",
      "13000 tweets queried of 17492 total tweets.\n",
      "13100 tweets queried of 17492 total tweets.\n",
      "13200 tweets queried of 17492 total tweets.\n",
      "13300 tweets queried of 17492 total tweets.\n",
      "13400 tweets queried of 17492 total tweets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13500 tweets queried of 17492 total tweets.\n",
      "13600 tweets queried of 17492 total tweets.\n",
      "13700 tweets queried of 17492 total tweets.\n",
      "13800 tweets queried of 17492 total tweets.\n",
      "13900 tweets queried of 17492 total tweets.\n",
      "14000 tweets queried of 17492 total tweets.\n",
      "14100 tweets queried of 17492 total tweets.\n",
      "14200 tweets queried of 17492 total tweets.\n",
      "14300 tweets queried of 17492 total tweets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14400 tweets queried of 17492 total tweets.\n",
      "14500 tweets queried of 17492 total tweets.\n",
      "14600 tweets queried of 17492 total tweets.\n",
      "14700 tweets queried of 17492 total tweets.\n",
      "14800 tweets queried of 17492 total tweets.\n",
      "14900 tweets queried of 17492 total tweets.\n",
      "15000 tweets queried of 17492 total tweets.\n",
      "15100 tweets queried of 17492 total tweets.\n",
      "15200 tweets queried of 17492 total tweets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15300 tweets queried of 17492 total tweets.\n",
      "15400 tweets queried of 17492 total tweets.\n",
      "15500 tweets queried of 17492 total tweets.\n",
      "15600 tweets queried of 17492 total tweets.\n",
      "15700 tweets queried of 17492 total tweets.\n",
      "15800 tweets queried of 17492 total tweets.\n",
      "15900 tweets queried of 17492 total tweets.\n",
      "16000 tweets queried of 17492 total tweets.\n",
      "16100 tweets queried of 17492 total tweets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16200 tweets queried of 17492 total tweets.\n",
      "16300 tweets queried of 17492 total tweets.\n",
      "16400 tweets queried of 17492 total tweets.\n",
      "16500 tweets queried of 17492 total tweets.\n",
      "16600 tweets queried of 17492 total tweets.\n",
      "16700 tweets queried of 17492 total tweets.\n",
      "16800 tweets queried of 17492 total tweets.\n",
      "16900 tweets queried of 17492 total tweets.\n",
      "17000 tweets queried of 17492 total tweets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17100 tweets queried of 17492 total tweets.\n",
      "17200 tweets queried of 17492 total tweets.\n",
      "17300 tweets queried of 17492 total tweets.\n",
      "17400 tweets queried of 17492 total tweets.\n",
      "There were 6193 total errors of 17492 total tweets.\n",
      "    Label 0 had 439 errors.\n",
      "    Label 1 had 34 errors.\n",
      "    Label 2 had 350 errors.\n",
      "    Label 3 had 26 errors.\n",
      "    Label 4 had 661 errors.\n",
      "    Label 5 had 4683 errors.\n",
      "CPU times: user 2min 41s, sys: 7.83 s, total: 2min 49s\n",
      "Wall time: 4h 34min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# query tweets\n",
    "tweet_df, error_df = queryTweets(tweet_df=id_df,\n",
    "                                 api=api,\n",
    "                                 tweet_filepath_out='../data/derived/tweets_query.csv',\n",
    "                                 error_filepath_out='../data/derived/track_error_query.csv',\n",
    "                                 all_tweets=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "annual-creek",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>597576902212063232</td>\n",
       "      <td>Cisco had to deal with a fat cash payout to th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>565586175864610817</td>\n",
       "      <td>@MadamPlumpette I'm decent at editing, no worr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563881580209246209</td>\n",
       "      <td>@girlziplocked will read. gotta go afk for a b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>595380689534656512</td>\n",
       "      <td>guys. show me the data. show me your github. t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>563757610327748608</td>\n",
       "      <td>@tpw_rules nothings broken. I was just driving...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>563082741370339330</td>\n",
       "      <td>ur face is classified as a utility by the FCC.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>596962098845851648</td>\n",
       "      <td>@lysandraws yay! Absolutely. I'm not gone unti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>563874350038675457</td>\n",
       "      <td>RT @kashiichan: \"It really feels like the @twi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>597240424873394176</td>\n",
       "      <td>@SirenSailor rtfm. http://t.co/jaMXHikl3u</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>571030421103910912</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                               text  \\\n",
       "0  597576902212063232  Cisco had to deal with a fat cash payout to th...   \n",
       "1  565586175864610817  @MadamPlumpette I'm decent at editing, no worr...   \n",
       "2  563881580209246209  @girlziplocked will read. gotta go afk for a b...   \n",
       "3  595380689534656512  guys. show me the data. show me your github. t...   \n",
       "4  563757610327748608  @tpw_rules nothings broken. I was just driving...   \n",
       "5  563082741370339330     ur face is classified as a utility by the FCC.   \n",
       "6  596962098845851648  @lysandraws yay! Absolutely. I'm not gone unti...   \n",
       "7  563874350038675457  RT @kashiichan: \"It really feels like the @twi...   \n",
       "8  597240424873394176          @SirenSailor rtfm. http://t.co/jaMXHikl3u   \n",
       "9  571030421103910912                                               None   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "5      0  \n",
       "6      0  \n",
       "7      0  \n",
       "8      0  \n",
       "9      1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick peek\n",
    "tweet_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-intellectual",
   "metadata": {},
   "source": [
    "# Data dictionary\n",
    "\n",
    "`tweet_id` integer with tweet ID to query from twitter API\n",
    "\n",
    "`text` text body of tweet\n",
    "\n",
    "`label` boolean for label from datasets\n",
    "* 0. neither, expert label from Waseem 2016\n",
    "* 1. racist, expert label from Waseem 2016\n",
    "* 2. sexist, expert label from Waseem 2016\n",
    "* 3. both, expert label from Waseem 2016\n",
    "* 4. hostile, label from Jha and Mamidi 2017\n",
    "* 5. benevolent, label from Jha and Mamidi 2017\n",
    "\n",
    "# References\n",
    "* [Jha and Mamidi 2017](https://www.aclweb.org/anthology/W17-2902.pdf)\n",
    "* [Waseem 2016](https://www.aclweb.org/anthology/W16-5618.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
