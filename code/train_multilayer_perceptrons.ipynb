{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "annoying-surveillance",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afraid-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "extensive-mambo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create global variable to use for random seed as needed\n",
    "random_seed = 466"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perfect-newspaper",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "further-agriculture",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tweet_df(dataset_name):\n",
    "    \"\"\"\n",
    "    Load tweet dataframes (assumes filename structure)\n",
    "    \"\"\"\n",
    "    filepath_in = f'../data/derived/tweets_supervised_{dataset_name}.csv'\n",
    "    df = pd.read_csv(filepath_in)\n",
    "    return df\n",
    "\n",
    "def load_tweet_vectors(vector_name, dataset_name):\n",
    "    \"\"\"\n",
    "    Load tweet vectors (assumes filename structure)\n",
    "    \"\"\"\n",
    "    \n",
    "    # load LSI vectors (saved as array in CSV file)\n",
    "    if 'lsi' in vector_name:\n",
    "        filepath_in = f'../data/derived/vectors/vector{vector_name}_{dataset_name}.csv'\n",
    "        vectors = np.loadtxt(filepath_in, delimiter=',')\n",
    "        \n",
    "    # load other vectors (saved as sparse array in NPZ file)\n",
    "    else:\n",
    "        filepath_in = f'../data/derived/vectors/vector{vector_name}_{dataset_name}.npz'\n",
    "        vectors = scipy.sparse.load_npz(filepath_in)\n",
    "        \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-softball",
   "metadata": {},
   "source": [
    "## Train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "close-tiger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multilayer_perceptron(vectors, df, alpha, random_seed, vector_name):\n",
    "    \"\"\"\n",
    "    Train multilayer perceptron with provided features, labels, alpha and random seed\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize classifier with default arguments\n",
    "    multilayer_perceptron = MLPClassifier(alpha = alpha, random_state = random_seed)\n",
    "\n",
    "    # train classifier\n",
    "    multilayer_perceptron.fit(X = vectors, y = df['label'])\n",
    "    \n",
    "    # write to file\n",
    "    filepath_out = f'../data/derived/models/mlp_vector{vector_name}_alpha{alpha}.pkl'\n",
    "    pickle.dump(multilayer_perceptron, open(filepath_out, 'wb'))\n",
    "    \n",
    "    return multilayer_perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-catalog",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "outer-ivory",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_multilayer_perceptron(multilayer_perceptron, vectors, df, dataset_name, vector_name):\n",
    "    \"\"\"\n",
    "    Generate predictions with trained multilayer perceptron classifier\n",
    "    \"\"\"\n",
    "    # generate predictions with classifier\n",
    "    predictions = multilayer_perceptron.predict(X = vectors)\n",
    "    \n",
    "    # create dataframe with record IDs, labels, and predicted labels\n",
    "    df = pd.DataFrame(data={'tweet_id':df['tweet_id'], 'label':df['label'], 'prediction':predictions})\n",
    "    \n",
    "    # write dataframe to file\n",
    "    filepath_out = f'../data/derived/predictions/mlp_vector{vector_name}_alpha{multilayer_perceptron.alpha}_{dataset_name}.csv'\n",
    "    df.to_csv(filepath_out, index=False)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-parker",
   "metadata": {},
   "source": [
    "## Evaluate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "authorized-sleep",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_multilayer_perceptron(labels, predictions, alpha, dataset_name, vector_name):\n",
    "    \"\"\"\n",
    "    Calculate accuracy, confusion matrix, support, precision, recall and F1 score and write to CSV\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize empty dictionary to store metrics\n",
    "    metrics = dict()\n",
    "    \n",
    "    # calculate and store confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true = labels, y_pred = predictions).ravel()\n",
    "    metrics['true_positives']  = tp\n",
    "    metrics['false_positives'] = fp\n",
    "    metrics['true_negatives']  = tn\n",
    "    metrics['false_negatives'] = fn\n",
    "    \n",
    "    # calculate and store accuracy\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    metrics['accuracy'] = accuracy\n",
    "    \n",
    "    # calculate and store macro precision, recall and F1 score\n",
    "    macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(y_true = labels,\n",
    "                                                                                 y_pred = predictions,\n",
    "                                                                                 average='macro')\n",
    "    metrics['macro_recall']    = macro_recall\n",
    "    metrics['macro_precision'] = macro_precision\n",
    "    metrics['macro_f1']        = macro_f1\n",
    "    \n",
    "    # calculate and store micro precision, recall and F1 score\n",
    "    micro_precision, micro_recall, micro_f1, _ = precision_recall_fscore_support(y_true = labels,\n",
    "                                                                                 y_pred = predictions,\n",
    "                                                                                 average='micro')\n",
    "    metrics['micro_recall']    = micro_recall\n",
    "    metrics['micro_precision'] = micro_precision\n",
    "    metrics['micro_f1']        = micro_f1\n",
    "    \n",
    "    # calculate and store binary precision, recall and F1 score\n",
    "    binary_precision, binary_recall, binary_f1, _ = precision_recall_fscore_support(y_true = labels,\n",
    "                                                                                    y_pred = predictions,\n",
    "                                                                                    average='binary')       \n",
    "    metrics['binary_recall']    = binary_recall\n",
    "    metrics['binary_precision'] = binary_precision\n",
    "    metrics['binary_f1']        = binary_f1\n",
    "    \n",
    "    # create dataframe\n",
    "    metrics_df = pd.DataFrame(data=list(metrics.items()), columns=['metric','value'])\n",
    "    \n",
    "    # write dataframe to CSV\n",
    "    filepath_out = f'../data/derived/performance/mlp_vector{vector_name}_alpha{alpha}_{dataset_name}.csv'\n",
    "    metrics_df.to_csv(path_or_buf = filepath_out, index = False)\n",
    "    \n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-youth",
   "metadata": {},
   "source": [
    "## Train, predict and evaluate in one function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "recent-roommate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron(vector_name, alpha, random_seed):\n",
    "    \n",
    "    # load tweet dataframes\n",
    "    train_df = load_tweet_df('train')\n",
    "    dev_df   = load_tweet_df('dev')\n",
    "    \n",
    "    # load tweet vectors\n",
    "    train_vectors = load_tweet_vectors(vector_name, 'train')\n",
    "    dev_vectors   = load_tweet_vectors(vector_name, 'dev')\n",
    "    \n",
    "    # train multilayer perceptron classifier\n",
    "    multilayer_perceptron = train_multilayer_perceptron(train_vectors, train_df, alpha, random_seed, vector_name)\n",
    "    \n",
    "    # generate predictions for multilayer perceptron classifier\n",
    "    predictions_train = predict_multilayer_perceptron(multilayer_perceptron, train_vectors, train_df, 'train', vector_name)\n",
    "    predictions_dev   = predict_multilayer_perceptron(multilayer_perceptron, dev_vectors,   dev_df,   'dev',   vector_name)\n",
    "    \n",
    "    # evaluate predictions for multilayer perceptron classifier and write to CSV\n",
    "    metrics_train = evaluate_multilayer_perceptron(train_df['label'], predictions_train, alpha, 'train', vector_name)\n",
    "    metrics_dev   = evaluate_multilayer_perceptron(dev_df['label'],   predictions_dev,   alpha, 'dev',   vector_name)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-belarus",
   "metadata": {},
   "source": [
    "## Fit models with multiple vectors and regularization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "under-collaboration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize list of regularization parameters\n",
    "alpha_list = [0.0001, 0.01, 1, 10]\n",
    "\n",
    "# initialize list of vector names\n",
    "vector_name_list = ['count', 'tfidf', 'lsi5', 'lsi10', 'lsi50', 'lsi100']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "primary-adolescent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilayer perceptron with alpha 0.0001 and vector count complete.\n",
      "Multilayer perceptron with alpha 0.0001 and vector tfidf complete.\n",
      "Multilayer perceptron with alpha 0.0001 and vector lsi5 complete.\n",
      "Multilayer perceptron with alpha 0.0001 and vector lsi10 complete.\n",
      "Multilayer perceptron with alpha 0.0001 and vector lsi50 complete.\n",
      "Multilayer perceptron with alpha 0.0001 and vector lsi100 complete.\n",
      "Multilayer perceptron with alpha 0.01 and vector count complete.\n",
      "Multilayer perceptron with alpha 0.01 and vector tfidf complete.\n",
      "Multilayer perceptron with alpha 0.01 and vector lsi5 complete.\n",
      "Multilayer perceptron with alpha 0.01 and vector lsi10 complete.\n",
      "Multilayer perceptron with alpha 0.01 and vector lsi50 complete.\n",
      "Multilayer perceptron with alpha 0.01 and vector lsi100 complete.\n",
      "Multilayer perceptron with alpha 1 and vector count complete.\n",
      "Multilayer perceptron with alpha 1 and vector tfidf complete.\n",
      "Multilayer perceptron with alpha 1 and vector lsi5 complete.\n",
      "Multilayer perceptron with alpha 1 and vector lsi10 complete.\n",
      "Multilayer perceptron with alpha 1 and vector lsi50 complete.\n",
      "Multilayer perceptron with alpha 1 and vector lsi100 complete.\n",
      "Multilayer perceptron with alpha 10 and vector count complete.\n",
      "Multilayer perceptron with alpha 10 and vector tfidf complete.\n",
      "Multilayer perceptron with alpha 10 and vector lsi5 complete.\n",
      "Multilayer perceptron with alpha 10 and vector lsi10 complete.\n",
      "Multilayer perceptron with alpha 10 and vector lsi50 complete.\n",
      "Multilayer perceptron with alpha 10 and vector lsi100 complete.\n"
     ]
    }
   ],
   "source": [
    "# iterate over regularization parameters\n",
    "for alpha in alpha_list:\n",
    "    \n",
    "    # iterate over list of vector names\n",
    "    for vector_name in vector_name_list:\n",
    "        \n",
    "        # train multilayer perceptron\n",
    "        multilayer_perceptron(vector_name, alpha, random_seed)\n",
    "        print(f'Multilayer perceptron with alpha {alpha} and vector {vector_name} complete.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
