{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eight-durham",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "technical-december",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "russian-despite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed for reproducibility as global variable\n",
    "RANDOM_SEED = 466"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-revision",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "moderate-vertex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>597576902212063232</td>\n",
       "      <td>Cisco had to deal with a fat cash payout to th...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>565586175864610817</td>\n",
       "      <td>@MadamPlumpette I'm decent at editing, no worr...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563881580209246209</td>\n",
       "      <td>@girlziplocked will read. gotta go afk for a b...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>595380689534656512</td>\n",
       "      <td>guys. show me the data. show me your github. t...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>563757610327748608</td>\n",
       "      <td>@tpw_rules nothings broken. I was just driving...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                               text  \\\n",
       "0  597576902212063232  Cisco had to deal with a fat cash payout to th...   \n",
       "1  565586175864610817  @MadamPlumpette I'm decent at editing, no worr...   \n",
       "2  563881580209246209  @girlziplocked will read. gotta go afk for a b...   \n",
       "3  595380689534656512  guys. show me the data. show me your github. t...   \n",
       "4  563757610327748608  @tpw_rules nothings broken. I was just driving...   \n",
       "\n",
       "   label  \n",
       "0    0.0  \n",
       "1    0.0  \n",
       "2    0.0  \n",
       "3    0.0  \n",
       "4    0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load cleaned tweets dataset\n",
    "filepath_in = '../data/derived/tweets_clean.csv'\n",
    "tweet_df = pd.read_csv(filepath_or_buffer=filepath_in)\n",
    "# preview dataframe\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-amateur",
   "metadata": {},
   "source": [
    "# Split data into stratified train, development and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-closure",
   "metadata": {},
   "source": [
    "I will get a stratified sample from each label (i.e. not sexist or racist, sexist, racist, both, hostile sexist, benevolent sexist) and each original dataset (i.e. Waseem 2016 and Jha Mamidi 2017) into the training, development, and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "covered-timber",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_subset(tweet_df, label, split_proportions):\n",
    "    \n",
    "    \"\"\"\n",
    "    Split dataset with label into specified proportions\n",
    "    \"\"\"\n",
    "    \n",
    "    # subset and shuffle dataset\n",
    "    # subset tweet_df by label\n",
    "    subset_df = tweet_df[tweet_df['label']==label]\n",
    "    # shuffle subset\n",
    "    shuffled_df = subset_df.sample(random_state=RANDOM_SEED, frac=1)\n",
    "    # reset index of subset\n",
    "    shuffled_df.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    # split dataset\n",
    "    # extract proportions to split dataset\n",
    "    train_proportion, dev_proportion, test_proportion = split_proportions\n",
    "    # extract number of records from shuffled dataframe\n",
    "    num_records = len(shuffled_df)\n",
    "    # calculate indices where to split dataframe into proportions of the dataset\n",
    "    where_to_split = np.trunc([num_records * (train_proportion),\n",
    "                               num_records * (train_proportion + dev_proportion)]).astype(int)\n",
    "    # split dataset at indices\n",
    "    train_df, dev_df, test_df = np.split(shuffled_df, where_to_split)\n",
    "    \n",
    "    return train_df, dev_df, test_df\n",
    "\n",
    "def split_dataset(tweet_df, split_proportions):\n",
    "    \"\"\"\n",
    "    Split dataset into specified proportions with balanced distribution of labels\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize empty lists for each dataset\n",
    "    train_df_list = []\n",
    "    test_df_list  = []\n",
    "    dev_df_list   = []\n",
    "    \n",
    "    # iterate over labels\n",
    "    for label in set(tweet_df['label']):\n",
    "        # split dataset with label into specified proportions\n",
    "        train_subset_df, dev_subset_df, test_subset_df = split_subset(tweet_df, label=label, split_proportions=(0.7,0.15,0.15))\n",
    "        # append dataframes to dataframe lists\n",
    "        train_df_list.append(train_subset_df)\n",
    "        test_df_list.append(test_subset_df)\n",
    "        dev_df_list.append(dev_subset_df)\n",
    "    \n",
    "    # stack dataframes in lists to create training, test and development datasets\n",
    "    train_df = pd.concat(train_df_list, ignore_index=True)\n",
    "    test_df = pd.concat(test_df_list, ignore_index=True)\n",
    "    dev_df = pd.concat(dev_df_list, ignore_index=True)\n",
    "    \n",
    "    return train_df, test_df, dev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "executive-feeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train, test and development datasets with\n",
    "train_df, test_df, dev_df = split_dataset(tweet_df, split_proportions=(0.7,0.15,0.15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-vermont",
   "metadata": {},
   "source": [
    "# Track sample size of each label by dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-norwegian",
   "metadata": {},
   "source": [
    "I will ensure each dataset has a comparable proportion of records from each label and original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "minor-herald",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_count</th>\n",
       "      <th>train_percent</th>\n",
       "      <th>dev_count</th>\n",
       "      <th>dev_percent</th>\n",
       "      <th>test_count</th>\n",
       "      <th>test_percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>3768.0</td>\n",
       "      <td>57.995998</td>\n",
       "      <td>807.0</td>\n",
       "      <td>57.932520</td>\n",
       "      <td>808.0</td>\n",
       "      <td>57.879656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>44.0</td>\n",
       "      <td>0.677236</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.717875</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.716332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>344.0</td>\n",
       "      <td>5.294751</td>\n",
       "      <td>74.0</td>\n",
       "      <td>5.312276</td>\n",
       "      <td>74.0</td>\n",
       "      <td>5.300860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.246268</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.287150</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.286533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>1901.0</td>\n",
       "      <td>29.259658</td>\n",
       "      <td>407.0</td>\n",
       "      <td>29.217516</td>\n",
       "      <td>408.0</td>\n",
       "      <td>29.226361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>424.0</td>\n",
       "      <td>6.526089</td>\n",
       "      <td>91.0</td>\n",
       "      <td>6.532663</td>\n",
       "      <td>92.0</td>\n",
       "      <td>6.590258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>6497.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1393.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1396.0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_count  train_percent  dev_count  dev_percent  test_count  \\\n",
       "label                                                                   \n",
       "0.0         3768.0      57.995998      807.0    57.932520       808.0   \n",
       "1.0           44.0       0.677236       10.0     0.717875        10.0   \n",
       "2.0          344.0       5.294751       74.0     5.312276        74.0   \n",
       "3.0           16.0       0.246268        4.0     0.287150         4.0   \n",
       "4.0         1901.0      29.259658      407.0    29.217516       408.0   \n",
       "5.0          424.0       6.526089       91.0     6.532663        92.0   \n",
       "total       6497.0     100.000000     1393.0   100.000000      1396.0   \n",
       "\n",
       "       test_percent  \n",
       "label                \n",
       "0.0       57.879656  \n",
       "1.0        0.716332  \n",
       "2.0        5.300860  \n",
       "3.0        0.286533  \n",
       "4.0       29.226361  \n",
       "5.0        6.590258  \n",
       "total    100.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize empty dataframe to track size\n",
    "track_size_df = pd.DataFrame()\n",
    "\n",
    "# input counts of each training set\n",
    "track_size_df['train_count'] = train_df.groupby('label')['text'].count()\n",
    "track_size_df['dev_count'] = dev_df.groupby('label')['text'].count()\n",
    "track_size_df['test_count'] = test_df.groupby('label')['text'].count()\n",
    "\n",
    "# sum total sample size at each step\n",
    "track_size_df.loc['total',:] = np.sum(track_size_df)\n",
    "\n",
    "# initialize empty list to track column order, alternating count and percent throughout datasets\n",
    "new_col_order = []\n",
    "\n",
    "# iterate through columns\n",
    "for col in track_size_df.columns:\n",
    "    \n",
    "    # store dataset name\n",
    "    prefix = col[:-6]\n",
    "    # add percent before step name\n",
    "    percent_col = prefix + '_percent'\n",
    "    # add column names to list\n",
    "    new_col_order.append(col)\n",
    "    new_col_order.append(percent_col)\n",
    "    \n",
    "    # calculate percent of dataset at each label\n",
    "    track_size_df[percent_col] = (track_size_df[col] / track_size_df.loc['total',col]) * 100\n",
    "\n",
    "# reorder columns\n",
    "track_size_df = track_size_df[new_col_order]\n",
    "\n",
    "# preview dataframe\n",
    "track_size_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "revolutionary-scheme",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to csv\n",
    "track_size_filepath_out = '../data/derived/track_size_split.csv'\n",
    "track_size_df.to_csv(path_or_buf=track_size_filepath_out, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-cuisine",
   "metadata": {},
   "source": [
    "# Map labels for supervised project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-disability",
   "metadata": {},
   "source": [
    "Now that I have a stratified sample of records by each label and dataset of original in my training, development, and testing datasets, I am going to change the labels. For the supervised portion of my project, I am classifying labels as not sexist or sexist. I will map the more specific labels provided by the original dataset to these less specific labels.\n",
    "\n",
    "| Old label | Old meaning | New label | New meaning |\n",
    "| --------- | ----------- | --------- | ----------- |\n",
    "| 0 | Not racist or sexist according to expert opinion (Waseem 2016) | 0 | Not sexist |\n",
    "| 1 | Racist and not sexist according to expert opinion (Waseem 2016) | 0 | Not sexist |\n",
    "| 2 | Sexist and not racist according to expert opinion (Waseem 2016) | 1 | Sexist |\n",
    "| 3 | Racist and sexist according to expert opinion (Waseem 2016) | 1 | Sexist |\n",
    "| 4 | Hostile sexist (Jha Mamidi 2017) | 1 | Sexist |\n",
    "| 5 | Benevolent sexist (Jha Mamidi 2017) | 1 | Sexist |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "speaking-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary to map old to new labels\n",
    "old_to_new_labels = {0:0, 1:0, 2:1, 3:1, 4:1, 5:1}\n",
    "\n",
    "# map old to new labels for training, development, and test datasets\n",
    "train_df['label'] = train_df['label'].map(old_to_new_labels)\n",
    "dev_df['label'] = dev_df['label'].map(old_to_new_labels)\n",
    "test_df['label'] = test_df['label'].map(old_to_new_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-investment",
   "metadata": {},
   "source": [
    "# Write supervised datasets to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "rising-affect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write training data to csv\n",
    "train_df_filepath_out = '../data/derived/tweets_supervised_train.csv'\n",
    "train_df.to_csv(path_or_buf=train_df_filepath_out, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "tropical-style",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write development data to csv\n",
    "dev_df_filepath_out = '../data/derived/tweets_supervised_dev.csv'\n",
    "dev_df.to_csv(path_or_buf=dev_df_filepath_out, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "guided-hydrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write testing data to csv\n",
    "test_df_filepath_out = '../data/derived/tweets_supervised_test.csv'\n",
    "test_df.to_csv(path_or_buf=test_df_filepath_out, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smaller-relations",
   "metadata": {},
   "source": [
    "# Track sample size of each label by dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "opponent-moore",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_count</th>\n",
       "      <th>train_percent</th>\n",
       "      <th>dev_count</th>\n",
       "      <th>dev_percent</th>\n",
       "      <th>test_count</th>\n",
       "      <th>test_percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3812.0</td>\n",
       "      <td>58.673234</td>\n",
       "      <td>817.0</td>\n",
       "      <td>58.650395</td>\n",
       "      <td>818.0</td>\n",
       "      <td>58.595989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2685.0</td>\n",
       "      <td>41.326766</td>\n",
       "      <td>576.0</td>\n",
       "      <td>41.349605</td>\n",
       "      <td>578.0</td>\n",
       "      <td>41.404011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>6497.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1393.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1396.0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_count  train_percent  dev_count  dev_percent  test_count  \\\n",
       "label                                                                   \n",
       "0           3812.0      58.673234      817.0    58.650395       818.0   \n",
       "1           2685.0      41.326766      576.0    41.349605       578.0   \n",
       "total       6497.0     100.000000     1393.0   100.000000      1396.0   \n",
       "\n",
       "       test_percent  \n",
       "label                \n",
       "0         58.595989  \n",
       "1         41.404011  \n",
       "total    100.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize empty dataframe to track size\n",
    "track_size_supervised_df = pd.DataFrame()\n",
    "\n",
    "# input counts of each training set\n",
    "track_size_supervised_df['train_count'] = train_df.groupby('label')['text'].count()\n",
    "track_size_supervised_df['dev_count'] = dev_df.groupby('label')['text'].count()\n",
    "track_size_supervised_df['test_count'] = test_df.groupby('label')['text'].count()\n",
    "\n",
    "# sum total sample size at each step\n",
    "track_size_supervised_df.loc['total',:] = np.sum(track_size_supervised_df)\n",
    "\n",
    "# initialize empty list to track column order, alternating count and percent throughout datasets\n",
    "new_col_order = []\n",
    "\n",
    "# iterate through columns\n",
    "for col in track_size_supervised_df.columns:\n",
    "    \n",
    "    # store dataset name\n",
    "    prefix = col[:-6]\n",
    "    # add percent before step name\n",
    "    percent_col = prefix + '_percent'\n",
    "    # add column names to list\n",
    "    new_col_order.append(col)\n",
    "    new_col_order.append(percent_col)\n",
    "    \n",
    "    # calculate percent of dataset at each label\n",
    "    track_size_supervised_df[percent_col] = (track_size_supervised_df[col] / track_size_supervised_df.loc['total',col]) * 100\n",
    "\n",
    "# reorder columns\n",
    "track_size_supervised_df = track_size_supervised_df[new_col_order]\n",
    "\n",
    "# preview dataframe\n",
    "track_size_supervised_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "applicable-behalf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to csv\n",
    "track_size_supervised_filepath_out = '../data/derived/track_size_supervised_split.csv'\n",
    "track_size_supervised_df.to_csv(path_or_buf=track_size_supervised_filepath_out, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
