{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "exterior-aviation",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "liquid-technique",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import homogeneity_score, completeness_score, adjusted_rand_score, calinski_harabasz_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "external-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create global variable to use for random seed as needed\n",
    "random_seed = 466"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-customs",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "swedish-edition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_unsupervised_tweet_df():\n",
    "    \"\"\"\n",
    "    Load tweet dataframes (assumes filename structure)\n",
    "    \"\"\"\n",
    "    filepath_in = f'../data/derived/tweets_unsupervised.csv'\n",
    "    df = pd.read_csv(filepath_in)\n",
    "    return df\n",
    "\n",
    "def load_unsupervised_tweet_vectors(vector_name):\n",
    "    \"\"\"\n",
    "    Load tweet vectors (assumes filename structure)\n",
    "    \"\"\"\n",
    "    filepath_in = f'../data/derived/vectors/vector{vector_name}_unsupervised.npz'\n",
    "    vectors = scipy.sparse.load_npz(filepath_in)\n",
    "        \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-brush",
   "metadata": {},
   "source": [
    "## Fit clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "offensive-prophet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_clusters(num_clusters, vectors, random_seed, vector_name):\n",
    "    \"\"\"\n",
    "    Fit KMeans with provided number of clusters and vectors\n",
    "    \"\"\"\n",
    "    # initialize k-means\n",
    "    kmeans = KMeans(n_clusters = num_clusters, random_state = random_seed)\n",
    "\n",
    "    # train k-means\n",
    "    kmeans.fit(vectors)\n",
    "    \n",
    "    # write to file\n",
    "    filepath_out = f'../data/derived/models/kmeans_vector{vector_name}_clusters{num_clusters}.pkl'\n",
    "    pickle.dump(kmeans, open(filepath_out, 'wb'))\n",
    "    \n",
    "    return kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-republican",
   "metadata": {},
   "source": [
    "## Predict clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "frequent-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_clusters(kmeans, vectors, df, vector_name):\n",
    "    \"\"\"\n",
    "    Generate predictions with fit K-Means\n",
    "    \"\"\"\n",
    "    # gereate predictions\n",
    "    predictions = kmeans.predict(X = vectors)\n",
    "    \n",
    "    # create dataframe with record IDs, labels and predicted labels\n",
    "    df = pd.DataFrame(data={'tweet_id':df['tweet_id'], 'label':df['label'], 'prediction':predictions})\n",
    "    \n",
    "    # write dataframe to file\n",
    "    filepath_out = f'../data/derived/predictions/kmeans_vector{vector_name}_clusters{kmeans.n_clusters}.csv'\n",
    "    df.to_csv(filepath_out, index=False)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-yemen",
   "metadata": {},
   "source": [
    "## Evaluate clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hollow-summit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clusters(vectors, predictions, labels, subset_predictions, num_clusters, vector_name):\n",
    "    \"\"\"\n",
    "    Calculate homogeneity, completeness, adusted Rand, and Calinski Harabasz scores\n",
    "    \"\"\"\n",
    "    # initialize empty dictionary to store metrics\n",
    "    metrics = dict()\n",
    "    \n",
    "    # calculate metrics\n",
    "    calinski_harabasz = calinski_harabasz_score(vectors.toarray(), predictions)\n",
    "    homogeneity       = homogeneity_score(labels,   subset_predictions)\n",
    "    completeness      = completeness_score(labels,  subset_predictions)\n",
    "    adjusted_rand     = adjusted_rand_score(labels, subset_predictions)\n",
    "    \n",
    "    # store metrics\n",
    "    metrics['homogeneity']       = homogeneity\n",
    "    metrics['completeness']      = completeness\n",
    "    metrics['adjusted_rand']     = adjusted_rand\n",
    "    metrics['calinski_harabasz'] = calinski_harabasz\n",
    "    \n",
    "    # create dataframe\n",
    "    metrics_df = pd.DataFrame(data=list(metrics.items()), columns=['metric','value'])\n",
    "    \n",
    "    # write dataframe to CSV\n",
    "    filepath_out = f'../data/derived/performance/kmeans_vector{vector_name}_clusters{num_clusters}.csv'\n",
    "    metrics_df.to_csv(path_or_buf = filepath_out, index = False)\n",
    "    \n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-catholic",
   "metadata": {},
   "source": [
    "## Fit, predict, and evaluate in one function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "comparative-ceiling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(vector_name, num_clusters, random_seed):\n",
    "    \n",
    "    # load dataframe and vectors\n",
    "    tweet_df = load_unsupervised_tweet_df()\n",
    "    vectors  = load_unsupervised_tweet_vectors(vector_name)\n",
    "    \n",
    "    # fit kmeans\n",
    "    kmeans = fit_clusters(num_clusters, vectors, random_seed, vector_name)\n",
    "\n",
    "    # generate predictions for all tweets\n",
    "    predictions = predict_clusters(kmeans, vectors, tweet_df, vector_name)\n",
    "    \n",
    "    # get labels and labelled subset of predictions (used for metrics that require ground truth)\n",
    "    subset_idx = [i for i in range(len(tweet_df)) if tweet_df['label'][i] != 0]\n",
    "    subset_predictions = predictions[subset_idx]\n",
    "    labels = tweet_df.iloc[subset_idx, :]['label']\n",
    "\n",
    "    # evaluate clusters\n",
    "    evaluate_clusters(vectors, predictions, labels, subset_predictions, num_clusters, vector_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-africa",
   "metadata": {},
   "source": [
    "## Fit models with multiple vectors and number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faced-standard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize list of number of clusters\n",
    "num_clusters_list = [i for i in range(2, 11)]\n",
    "\n",
    "# initialize list of vector names\n",
    "vector_name_list = ['count', 'tfidf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "romance-lebanon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Means with num_clusters 2 and vector count complete.\n",
      "K-Means with num_clusters 2 and vector tfidf complete.\n",
      "K-Means with num_clusters 3 and vector count complete.\n",
      "K-Means with num_clusters 3 and vector tfidf complete.\n",
      "K-Means with num_clusters 4 and vector count complete.\n",
      "K-Means with num_clusters 4 and vector tfidf complete.\n",
      "K-Means with num_clusters 5 and vector count complete.\n",
      "K-Means with num_clusters 5 and vector tfidf complete.\n",
      "K-Means with num_clusters 6 and vector count complete.\n",
      "K-Means with num_clusters 6 and vector tfidf complete.\n",
      "K-Means with num_clusters 7 and vector count complete.\n",
      "K-Means with num_clusters 7 and vector tfidf complete.\n",
      "K-Means with num_clusters 8 and vector count complete.\n",
      "K-Means with num_clusters 8 and vector tfidf complete.\n",
      "K-Means with num_clusters 9 and vector count complete.\n",
      "K-Means with num_clusters 9 and vector tfidf complete.\n",
      "K-Means with num_clusters 10 and vector count complete.\n",
      "K-Means with num_clusters 10 and vector tfidf complete.\n"
     ]
    }
   ],
   "source": [
    "# iterate over number of clusters\n",
    "for num_clusters in num_clusters_list:\n",
    "    \n",
    "    # iterate over list of vector names\n",
    "    for vector_name in vector_name_list:\n",
    "        \n",
    "        # fit K-Means\n",
    "        kmeans(vector_name, num_clusters, random_seed)\n",
    "        print(f'K-Means with num_clusters {num_clusters} and vector {vector_name} complete.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
