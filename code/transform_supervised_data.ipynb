{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "vital-country",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-familiar",
   "metadata": {},
   "source": [
    "Load libraries and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "shaped-sperm",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize.casual import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pickle\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "alien-friday",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "train_df = pd.read_csv('../data/derived/tweets_supervised_train.csv')\n",
    "dev_df   = pd.read_csv('../data/derived/tweets_supervised_dev.csv')\n",
    "test_df  = pd.read_csv('../data/derived/tweets_supervised_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-immunology",
   "metadata": {},
   "source": [
    "Confirm datasets have expected size and format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "negative-victoria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6497 records.\n",
      "1393 records.\n",
      "1396 records.\n"
     ]
    }
   ],
   "source": [
    "for df in [train_df, dev_df, test_df]:\n",
    "    print(f'{len(df)} records.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pregnant-maker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3402</th>\n",
       "      <td>565353393955565568</td>\n",
       "      <td>@milfgaardian N'rage pink after ~1 week, turqu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>596029273665744896</td>\n",
       "      <td>hah. someone believes i was \"schooled\" instead...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3227</th>\n",
       "      <td>573270910729261056</td>\n",
       "      <td>We have @crashoverridenw, an invaluable resour...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id                                               text  \\\n",
       "3402  565353393955565568  @milfgaardian N'rage pink after ~1 week, turqu...   \n",
       "1129  596029273665744896  hah. someone believes i was \"schooled\" instead...   \n",
       "3227  573270910729261056  We have @crashoverridenw, an invaluable resour...   \n",
       "\n",
       "      label  \n",
       "3402      0  \n",
       "1129      0  \n",
       "3227      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unnecessary-triple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>568667538495651841</td>\n",
       "      <td>all of these quotes are from @wadhwa on @tldr.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>572328240993464320</td>\n",
       "      <td>Feminazi ðŸ˜³</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>563596116831125504</td>\n",
       "      <td>@LarryWest42 nah. Most of the trees here are p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweet_id                                               text  \\\n",
       "274  568667538495651841     all of these quotes are from @wadhwa on @tldr.   \n",
       "872  572328240993464320                                         Feminazi ðŸ˜³   \n",
       "498  563596116831125504  @LarryWest42 nah. Most of the trees here are p...   \n",
       "\n",
       "     label  \n",
       "274      0  \n",
       "872      1  \n",
       "498      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "coordinate-display",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>576516317882290176</td>\n",
       "      <td>@LauraaSilveira feminazi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>569720771863564288</td>\n",
       "      <td>@mistaphill Honestly... Belzer or Ric Ocasek o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>565365278138458112</td>\n",
       "      <td>@kencf0618 asking people to read some of the s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id                                               text  \\\n",
       "864   576516317882290176                           @LauraaSilveira feminazi   \n",
       "1065  569720771863564288  @mistaphill Honestly... Belzer or Ric Ocasek o...   \n",
       "209   565365278138458112  @kencf0618 asking people to read some of the s...   \n",
       "\n",
       "      label  \n",
       "864       1  \n",
       "1065      1  \n",
       "209       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-calcium",
   "metadata": {},
   "source": [
    "## Tokenize text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-cloud",
   "metadata": {},
   "source": [
    "Here, I lowercase and tokenize the text with NLTK's TweetTokenizer. In reality, this step of the analysis is done as part of vectorizing the data, but I added it here manually to explore the tokens created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bizarre-drive",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_tweet_text(df, dataset_name):\n",
    "    \"\"\"\n",
    "    Create tokenized text column in dataframe with text lowercased and then tokenized by NLTK's TweetTokenizer\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize tokenizer\n",
    "    tokenizer = TweetTokenizer()\n",
    "    # extract text\n",
    "    text = df['text']\n",
    "    # tokenize tweets and add to dataframe\n",
    "    df['tokenized_text'] = [tokenizer.tokenize(t.lower()) for t in text]\n",
    "    # reorder columns\n",
    "    df = df[['tweet_id','text','tokenized_text','label']]\n",
    "    # write to CSV\n",
    "    filepath_out = f'../data/derived/tweets_supervised_{dataset_name}_tokens.csv'\n",
    "    df.to_csv(path_or_buf=filepath_out, index=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "noticed-beauty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize text in datasets\n",
    "train_df = tokenize_tweet_text(train_df, 'train')\n",
    "dev_df   = tokenize_tweet_text(dev_df,   'dev')\n",
    "test_df  = tokenize_tweet_text(test_df,  'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-thickness",
   "metadata": {},
   "source": [
    "Confirm tokens match expectation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "tamil-palmer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>573246882501148672</td>\n",
       "      <td>RT @mercurypixel: @freebsdgirl At this point.....</td>\n",
       "      <td>[rt, @mercurypixel, :, @freebsdgirl, at, this,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>569200611415035904</td>\n",
       "      <td>plz stop posting pics of me that i posted a fe...</td>\n",
       "      <td>[plz, stop, posting, pics, of, me, that, i, po...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>564568918321147905</td>\n",
       "      <td>Been doing things. Going to have some pretty a...</td>\n",
       "      <td>[been, doing, things, ., going, to, have, some...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>573222765957816320</td>\n",
       "      <td>hello grafana/graphite/statsd server, let's se...</td>\n",
       "      <td>[hello, grafana, /, graphite, /, statsd, serve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>564632454179213312</td>\n",
       "      <td>@sschinke @TsundereRager previous versions of ...</td>\n",
       "      <td>[@sschinke, @tsundererager, previous, versions...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                               text  \\\n",
       "0  573246882501148672  RT @mercurypixel: @freebsdgirl At this point.....   \n",
       "1  569200611415035904  plz stop posting pics of me that i posted a fe...   \n",
       "2  564568918321147905  Been doing things. Going to have some pretty a...   \n",
       "3  573222765957816320  hello grafana/graphite/statsd server, let's se...   \n",
       "4  564632454179213312  @sschinke @TsundereRager previous versions of ...   \n",
       "\n",
       "                                      tokenized_text  label  \n",
       "0  [rt, @mercurypixel, :, @freebsdgirl, at, this,...      0  \n",
       "1  [plz, stop, posting, pics, of, me, that, i, po...      0  \n",
       "2  [been, doing, things, ., going, to, have, some...      0  \n",
       "3  [hello, grafana, /, graphite, /, statsd, serve...      0  \n",
       "4  [@sschinke, @tsundererager, previous, versions...      0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview dataframe\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-lodging",
   "metadata": {},
   "source": [
    "## Train count vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-argument",
   "metadata": {},
   "source": [
    "Here, I generate a bag of words representation of each tweet using sklearn's CountVectorizer on the tokenized tweet text. I do not remove stopwords, or remove words with a cutoff for high or low document frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "tribal-devon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_count_vectorizer(df, vectorizer_name):\n",
    "    \"\"\"\n",
    "    Train sklearn's CountVectorizer with text tokenized by NLTK's TweetTokenizer\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize vectorizer and tokenizer\n",
    "    vectorizer = CountVectorizer(tokenizer = TweetTokenizer().tokenize)\n",
    "    vectorizer.build_tokenizer()\n",
    "    # fit vectorizer to text\n",
    "    vectorizer.fit(df['text'])\n",
    "    \n",
    "    # write to file\n",
    "    filepath_out = f'../data/derived/{vectorizer_name}_vectorizer.pkl'\n",
    "    pickle.dump(vectorizer, open(filepath_out, 'wb'))\n",
    "    \n",
    "    return vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "comparative-crown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train vectorizer\n",
    "count_vectorizer = train_count_vectorizer(train_df, 'count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-giving",
   "metadata": {},
   "source": [
    "## Transform data into count vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "greek-implement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_vectorize(count_vectorizer, df, vectorizer_name, dataset_name):\n",
    "    \"\"\"\n",
    "    Use a trained CountVectorizer to transform text into count vectors\n",
    "    \"\"\"\n",
    "    \n",
    "    # transform data into count vectors\n",
    "    vectors = count_vectorizer.transform(df['text'])\n",
    "    \n",
    "    # save vectors to files\n",
    "    filepath_out = f'../data/derived/vectors/vector{vectorizer_name}_{dataset_name}.npz'\n",
    "    scipy.sparse.save_npz(filepath_out, vectors)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "agricultural-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data into count vectors\n",
    "train_vectors = count_vectorize(count_vectorizer, train_df, 'count', 'train')\n",
    "dev_vectors   = count_vectorize(count_vectorizer, dev_df,   'count', 'dev')\n",
    "test_vectors  = count_vectorize(count_vectorizer, test_df,  'count', 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-costs",
   "metadata": {},
   "source": [
    "Confirm vectors have expected format and shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acute-shoot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6497, 14740)    <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(1393, 14740)    <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(1396, 14740)    <class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "for vectors in [train_vectors, dev_vectors, test_vectors]:\n",
    "    print(f'{vectors.shape}    {type(vectors)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
