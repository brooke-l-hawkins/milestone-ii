{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "vital-country",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-familiar",
   "metadata": {},
   "source": [
    "Load libraries and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "shaped-sperm",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize.casual import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pickle\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "alien-friday",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "train_df = pd.read_csv('../data/derived/tweets_supervised_train.csv')\n",
    "dev_df   = pd.read_csv('../data/derived/tweets_supervised_dev.csv')\n",
    "test_df  = pd.read_csv('../data/derived/tweets_supervised_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-immunology",
   "metadata": {},
   "source": [
    "Confirm datasets have expected size and format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "negative-victoria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6497 records.\n",
      "1393 records.\n",
      "1396 records.\n"
     ]
    }
   ],
   "source": [
    "for df in [train_df, dev_df, test_df]:\n",
    "    print(f'{len(df)} records.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pregnant-maker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>597109858161197056</td>\n",
       "      <td>@BryanRenno blackmilk.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2511</th>\n",
       "      <td>603688341511495682</td>\n",
       "      <td>wtf is #BlameOneNotAll</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4303</th>\n",
       "      <td>570236419026886657</td>\n",
       "      <td>@thehiredmind You can have this one. Untag.  T...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id                                               text  \\\n",
       "2151  597109858161197056                             @BryanRenno blackmilk.   \n",
       "2511  603688341511495682                             wtf is #BlameOneNotAll   \n",
       "4303  570236419026886657  @thehiredmind You can have this one. Untag.  T...   \n",
       "\n",
       "      label  \n",
       "2151      0  \n",
       "2511      0  \n",
       "4303      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unnecessary-triple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>566700479606816768</td>\n",
       "      <td>So there. http://t.co/WbHonIZXaf</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>396088726524157952</td>\n",
       "      <td>RT @emilypoultney On Halloween girls should go...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>839859026066309120</td>\n",
       "      <td>RT @theCandidDiva: Girls r treasure to one's f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id                                               text  \\\n",
       "196   566700479606816768                   So there. http://t.co/WbHonIZXaf   \n",
       "1206  396088726524157952  RT @emilypoultney On Halloween girls should go...   \n",
       "1350  839859026066309120  RT @theCandidDiva: Girls r treasure to one's f...   \n",
       "\n",
       "      label  \n",
       "196       0  \n",
       "1206      1  \n",
       "1350      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "coordinate-display",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>599825575402864640</td>\n",
       "      <td>@adamsteinbaugh new life goal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>565363064510636032</td>\n",
       "      <td>.@pdlmma just general abuse. Not necessarily g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>567087489110650880</td>\n",
       "      <td>@mralext20 it worked fine for the first 30 sec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweet_id                                               text  \\\n",
       "146  599825575402864640                      @adamsteinbaugh new life goal   \n",
       "195  565363064510636032  .@pdlmma just general abuse. Not necessarily g...   \n",
       "361  567087489110650880  @mralext20 it worked fine for the first 30 sec...   \n",
       "\n",
       "     label  \n",
       "146      0  \n",
       "195      0  \n",
       "361      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-calcium",
   "metadata": {},
   "source": [
    "## Tokenize text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-cloud",
   "metadata": {},
   "source": [
    "Here, I lowercase and tokenize the text with NLTK's TweetTokenizer. In reality, this step of the analysis is done as part of vectorizing the data, but I added it here manually to explore the tokens created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bizarre-drive",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_tweet_text(df, dataset_name):\n",
    "    \"\"\"\n",
    "    Create tokenized text column in dataframe with text lowercased and then tokenized by NLTK's TweetTokenizer\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize tokenizer\n",
    "    tokenizer = TweetTokenizer()\n",
    "    # extract text\n",
    "    text = df['text']\n",
    "    # tokenize tweets and add to dataframe\n",
    "    df['tokenized_text'] = [tokenizer.tokenize(t.lower()) for t in text]\n",
    "    # reorder columns\n",
    "    df = df[['tweet_id','text','tokenized_text','label']]\n",
    "    # write to CSV\n",
    "    filepath_out = f'../data/derived/tweets_supervised_{dataset_name}_tokens.csv'\n",
    "    df.to_csv(path_or_buf=filepath_out, index=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "noticed-beauty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize text in datasets\n",
    "train_df = tokenize_tweet_text(train_df, 'train')\n",
    "dev_df   = tokenize_tweet_text(dev_df,   'dev')\n",
    "test_df  = tokenize_tweet_text(test_df,  'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-thickness",
   "metadata": {},
   "source": [
    "Confirm tokens match expectation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "tamil-palmer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>573246882501148672</td>\n",
       "      <td>RT @mercurypixel: @freebsdgirl At this point.....</td>\n",
       "      <td>[rt, @mercurypixel, :, @freebsdgirl, at, this,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>569200611415035904</td>\n",
       "      <td>plz stop posting pics of me that i posted a fe...</td>\n",
       "      <td>[plz, stop, posting, pics, of, me, that, i, po...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>564568918321147905</td>\n",
       "      <td>Been doing things. Going to have some pretty a...</td>\n",
       "      <td>[been, doing, things, ., going, to, have, some...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>573222765957816320</td>\n",
       "      <td>hello grafana/graphite/statsd server, let's se...</td>\n",
       "      <td>[hello, grafana, /, graphite, /, statsd, serve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>564632454179213312</td>\n",
       "      <td>@sschinke @TsundereRager previous versions of ...</td>\n",
       "      <td>[@sschinke, @tsundererager, previous, versions...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                               text  \\\n",
       "0  573246882501148672  RT @mercurypixel: @freebsdgirl At this point.....   \n",
       "1  569200611415035904  plz stop posting pics of me that i posted a fe...   \n",
       "2  564568918321147905  Been doing things. Going to have some pretty a...   \n",
       "3  573222765957816320  hello grafana/graphite/statsd server, let's se...   \n",
       "4  564632454179213312  @sschinke @TsundereRager previous versions of ...   \n",
       "\n",
       "                                      tokenized_text  label  \n",
       "0  [rt, @mercurypixel, :, @freebsdgirl, at, this,...      0  \n",
       "1  [plz, stop, posting, pics, of, me, that, i, po...      0  \n",
       "2  [been, doing, things, ., going, to, have, some...      0  \n",
       "3  [hello, grafana, /, graphite, /, statsd, serve...      0  \n",
       "4  [@sschinke, @tsundererager, previous, versions...      0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview dataframe\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-lodging",
   "metadata": {},
   "source": [
    "## Bag of words representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-argument",
   "metadata": {},
   "source": [
    "Here, I generate a bag of words representation of each tweet using sklearn's CountVectorizer on the tokenized tweet text. I do not remove stopwords, or remove words with a cutoff for high or low document frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "tribal-devon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_count_vectorizer(df, vectorizer_name):\n",
    "    \"\"\"\n",
    "    Train sklearn's CountVectorizer with text tokenized by NLTK's TweetTokenizer\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize vectorizer and tokenizer\n",
    "    vectorizer = CountVectorizer(tokenizer = TweetTokenizer().tokenize)\n",
    "    vectorizer.build_tokenizer()\n",
    "    # fit vectorizer to text\n",
    "    vectorizer.fit(df['text'])\n",
    "    \n",
    "    # write to file\n",
    "    filepath_out = f'../data/derived/models/vectorizer_{vectorizer_name}.pkl'\n",
    "    pickle.dump(vectorizer, open(filepath_out, 'wb'))\n",
    "    \n",
    "    return vectorizer\n",
    "\n",
    "def count_vectorize(count_vectorizer, df, vectorizer_name, dataset_name):\n",
    "    \"\"\"\n",
    "    Use a trained CountVectorizer to transform text into count vectors\n",
    "    \"\"\"\n",
    "    \n",
    "    # transform data into count vectors\n",
    "    vectors = count_vectorizer.transform(df['text'])\n",
    "    \n",
    "    # save vectors to files\n",
    "    filepath_out = f'../data/derived/vectors/vector{vectorizer_name}_{dataset_name}.npz'\n",
    "    scipy.sparse.save_npz(filepath_out, vectors)\n",
    "    \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "comparative-crown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train vectorizer\n",
    "count_vectorizer = train_count_vectorizer(train_df, 'count')\n",
    "\n",
    "# transform data into count vectors\n",
    "train_vectors = count_vectorize(count_vectorizer, train_df, 'count', 'train')\n",
    "dev_vectors   = count_vectorize(count_vectorizer, dev_df,   'count', 'dev')\n",
    "test_vectors  = count_vectorize(count_vectorizer, test_df,  'count', 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-costs",
   "metadata": {},
   "source": [
    "Confirm vectors have expected format and shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acute-shoot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6497, 14740)    <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(1393, 14740)    <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(1396, 14740)    <class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "for vectors in [train_vectors, dev_vectors, test_vectors]:\n",
    "    print(f'{vectors.shape}    {type(vectors)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
